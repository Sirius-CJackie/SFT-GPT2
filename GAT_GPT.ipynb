{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBXtGuMVWkY_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import scipy.sparse as sp\n",
        "import torch\n",
        "import pickle\n",
        "\n",
        "# This project incorporates partial code from [ChenxiLiu-HNU], \n",
        "# originally published at https://github.com/ChenxiLiu-HNU/ST-LLM.git.\n",
        "\n",
        "# We gratefully acknowledge their work.\n",
        "\n",
        "# Config dictionary with default values\n",
        "\n",
        "\n",
        "# Config dictionary with default values\n",
        "config = {\n",
        "    \"device\": \"cuda\",\n",
        "    \"data\": \"./dataset/\",\n",
        "    \"input_dim\": 3,\n",
        "    \"num_nodes\": 250,\n",
        "    \"input_len\": 12,\n",
        "    \"output_len\": 12,\n",
        "    \"batch_size\": 16,\n",
        "    \"lrate\": 1e-3,\n",
        "    \"llm_layer\": 1,\n",
        "    \"U\": 2,\n",
        "    \"epochs\": 200,\n",
        "    \"print_every\": 50,\n",
        "    \"wdecay\": 0.0001,\n",
        "    \"save\": \"./\",\n",
        "    \"es_patience\": 100,\n",
        "    \"dropout\":0.1,\n",
        "    \"channels\":64\n",
        "}\n",
        "\n",
        "def load_dataset(dataset_dir, batch_size, valid_batch_size=None, test_batch_size=None):\n",
        "    data = {}\n",
        "    for category in [\"train\", \"val\", \"test\"]:\n",
        "        cat_data = np.load(os.path.join(dataset_dir, category + \".npz\"))\n",
        "        data[\"x_\" + category] = cat_data[\"x\"]\n",
        "        data[\"y_\" + category] = cat_data[\"y\"]\n",
        "    scaler = StandardScaler(\n",
        "        mean=data[\"x_train\"][..., 0].mean(), std=data[\"x_train\"][..., 0].std()\n",
        "    )\n",
        "    # Data format\n",
        "    for category in [\"train\", \"val\", \"test\"]:\n",
        "        data[\"x_\" + category][..., 0] = scaler.transform(data[\"x_\" + category][..., 0])\n",
        "\n",
        "    print(\"Perform shuffle on the dataset\")\n",
        "    random_train = torch.arange(int(data[\"x_train\"].shape[0]))\n",
        "    random_train = torch.randperm(random_train.size(0))\n",
        "    data[\"x_train\"] = data[\"x_train\"][random_train, ...]\n",
        "    data[\"y_train\"] = data[\"y_train\"][random_train, ...]\n",
        "\n",
        "    random_val = torch.arange(int(data[\"x_val\"].shape[0]))\n",
        "    random_val = torch.randperm(random_val.size(0))\n",
        "    data[\"x_val\"] = data[\"x_val\"][random_val, ...]\n",
        "    data[\"y_val\"] = data[\"y_val\"][random_val, ...]\n",
        "    data[\"train_loader\"] = DataLoader(data[\"x_train\"], data[\"y_train\"], batch_size)\n",
        "    data[\"val_loader\"] = DataLoader(data[\"x_val\"], data[\"y_val\"], valid_batch_size)\n",
        "    data[\"test_loader\"] = DataLoader(data[\"x_test\"], data[\"y_test\"], test_batch_size)\n",
        "    data[\"scaler\"] = scaler\n",
        "\n",
        "    return data\n",
        "class DataLoader(object):\n",
        "    def __init__(self, xs, ys, batch_size, pad_with_last_sample=True):\n",
        "        self.batch_size = batch_size\n",
        "        self.current_ind = 0\n",
        "        if pad_with_last_sample:\n",
        "            num_padding = (batch_size - (len(xs) % batch_size)) % batch_size\n",
        "            x_padding = np.repeat(xs[-1:], num_padding, axis=0)\n",
        "            y_padding = np.repeat(ys[-1:], num_padding, axis=0)\n",
        "            xs = np.concatenate([xs, x_padding], axis=0)\n",
        "            ys = np.concatenate([ys, y_padding], axis=0)\n",
        "        self.size = len(xs)\n",
        "        self.num_batch = int(self.size // self.batch_size)\n",
        "        self.xs = xs\n",
        "        self.ys = ys\n",
        "\n",
        "    def shuffle(self):\n",
        "        permutation = np.random.permutation(self.size)\n",
        "        xs, ys = self.xs[permutation], self.ys[permutation]\n",
        "        self.xs = xs\n",
        "        self.ys = ys\n",
        "\n",
        "    def get_iterator(self):\n",
        "        self.current_ind = 0\n",
        "\n",
        "        def _wrapper():\n",
        "            while self.current_ind < self.num_batch:\n",
        "                start_ind = self.batch_size * self.current_ind\n",
        "                end_ind = min(self.size, self.batch_size * (self.current_ind + 1))\n",
        "                x_i = self.xs[start_ind:end_ind, ...]\n",
        "                y_i = self.ys[start_ind:end_ind, ...]\n",
        "                yield (x_i, y_i)\n",
        "                self.current_ind += 1\n",
        "\n",
        "        return _wrapper()\n",
        "\n",
        "\n",
        "class StandardScaler:\n",
        "    def __init__(self, mean, std):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def transform(self, data):\n",
        "        return (data - self.mean) / self.std\n",
        "\n",
        "    def inverse_transform(self, data):\n",
        "        return (data * self.std) + self.mean\n",
        "\n",
        "\n",
        "def MAE_torch(pred, true, mask_value=None):\n",
        "    if mask_value != None:\n",
        "        mask = torch.gt(true, mask_value)\n",
        "        pred = torch.masked_select(pred, mask)\n",
        "        true = torch.masked_select(true, mask)\n",
        "    return torch.mean(torch.abs(true - pred))\n",
        "\n",
        "\n",
        "def MAPE_torch(pred, true, mask_value=None):\n",
        "    if mask_value != None:\n",
        "        mask = torch.gt(true, mask_value)\n",
        "        pred = torch.masked_select(pred, mask)\n",
        "        true = torch.masked_select(true, mask)\n",
        "    return torch.mean(torch.abs(torch.div((true - pred), true)))\n",
        "\n",
        "\n",
        "def RMSE_torch(pred, true, mask_value=None):\n",
        "    if mask_value != None:\n",
        "        mask = torch.gt(true, mask_value)\n",
        "        pred = torch.masked_select(pred, mask)\n",
        "        true = torch.masked_select(true, mask)\n",
        "    return torch.sqrt(torch.mean((pred - true) ** 2))\n",
        "\n",
        "\n",
        "def WMAPE_torch(pred, true, mask_value=None):\n",
        "    if mask_value != None:\n",
        "        mask = torch.gt(true, mask_value)\n",
        "        pred = torch.masked_select(pred, mask)\n",
        "        true = torch.masked_select(true, mask)\n",
        "    loss = torch.sum(torch.abs(pred - true)) / torch.sum(torch.abs(true))\n",
        "    return loss\n",
        "\n",
        "def metric(pred, real):\n",
        "    mae = MAE_torch(pred, real, 0).item()\n",
        "    mape = MAPE_torch(pred, real,0).item()\n",
        "    wmape = WMAPE_torch(pred, real, 0).item()\n",
        "    rmse = RMSE_torch(pred, real, 0).item()\n",
        "    return mae, mape, rmse, wmape\n",
        "def load_graph_data(pkl_filename):\n",
        "    adj = load_pickle(pkl_filename)\n",
        "    return adj\n",
        "\n",
        "def load_pickle(pickle_file):\n",
        "    try:\n",
        "        with open(pickle_file, 'rb') as f:\n",
        "            pickle_data = pickle.load(f)\n",
        "            print(len(pickle_data))\n",
        "            print(pickle_data)\n",
        "            print(\"Type:\", type(pickle_data))  #\n",
        "            print(\"Shape:\", pickle_data.shape)\n",
        "\n",
        "    except UnicodeDecodeError as e:\n",
        "        with open(pickle_file, 'rb') as f:\n",
        "            pickle_data = pickle.load(f, encoding='latin1')\n",
        "    except Exception as e:\n",
        "        print('Unable to load data ', pickle_file, ':', e)\n",
        "        raise e\n",
        "\n",
        "    return pickle_data\n",
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "def seed_it(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ[\"PYTHONSEED\"] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.enabled = True\n",
        "    torch.manual_seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z0wvcOHcWX7l"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class GraphAttentionLayer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_features: int,\n",
        "        out_features: int,\n",
        "        n_heads: int,\n",
        "        is_concat: bool = True,\n",
        "        dropout: float = 0.1,\n",
        "        leaky_relu_negative_slope: float = 0.2,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.is_concat = is_concat\n",
        "        self.n_heads = n_heads\n",
        "\n",
        "        if is_concat:\n",
        "            assert out_features % n_heads == 0\n",
        "            self.n_hidden = out_features // n_heads\n",
        "        else:\n",
        "            self.n_hidden = out_features\n",
        "\n",
        "        self.proj = nn.Linear(in_features, self.n_hidden * n_heads, bias=False)\n",
        "        self.proj_attn = nn.Linear(in_features, self.n_hidden * n_heads // 2, bias=False)\n",
        "        self.attn = nn.Linear(self.n_hidden, 1, bias=False)\n",
        "        self.activation = nn.LeakyReLU(negative_slope=leaky_relu_negative_slope)\n",
        "        self.softmax = nn.Softmax(dim=2)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, h: torch.Tensor, adj_mat: torch.Tensor):\n",
        "        batch_size, n_nodes = h.shape[0:2]\n",
        "        g = self.proj(h).view(batch_size, n_nodes, self.n_heads, self.n_hidden)\n",
        "        ga = self.proj_attn(h).view(batch_size, n_nodes, self.n_heads, self.n_hidden // 2)\n",
        "        g_repeat = ga.repeat(1, n_nodes, 1, 1)\n",
        "        g_repeat_interleave = ga.repeat_interleave(n_nodes, dim=1)\n",
        "        g_concat = torch.cat([g_repeat_interleave, g_repeat], dim=-1)\n",
        "        g_concat = g_concat.view(\n",
        "            batch_size, n_nodes, n_nodes, self.n_heads, self.n_hidden\n",
        "        )\n",
        "\n",
        "        e = self.activation(self.attn(g_concat))\n",
        "        e = e.squeeze(-1)\n",
        "\n",
        "        assert adj_mat.shape[0] == 1 or adj_mat.shape[0] == n_nodes\n",
        "        assert adj_mat.shape[1] == 1 or adj_mat.shape[1] == n_nodes\n",
        "        assert adj_mat.shape[2] == 1 or adj_mat.shape[2] == self.n_heads\n",
        "\n",
        "        e = e.masked_fill(adj_mat < 0.5, float(\"-inf\"))\n",
        "\n",
        "        a = self.softmax(e)\n",
        "        a = self.dropout(a)\n",
        "\n",
        "        attn_res = torch.einsum(\"bijh,bjhf->bihf\", a, g)\n",
        "\n",
        "        if self.is_concat:\n",
        "            return attn_res.reshape(batch_size, n_nodes, self.n_heads * self.n_hidden)\n",
        "        else:\n",
        "            return attn_res.mean(dim=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PtTQAsNcWMUg"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers.models.gpt2.modeling_gpt2 import GPT2Model\n",
        "\n",
        "\n",
        "class GPT4TS(nn.Module):\n",
        "    def __init__(self, device=\"cuda:0\", gpt_layers=6):\n",
        "        super(GPT4TS, self).__init__()\n",
        "        self.gpt2 = GPT2Model.from_pretrained(\n",
        "            \"gpt2\", output_attentions=True, output_hidden_states=True\n",
        "        )\n",
        "        self.gpt2.h = self.gpt2.h[:gpt_layers]\n",
        "        print(\"gpt2 = {}\".format(self.gpt2))\n",
        "\n",
        "        for i, (name, param) in enumerate(self.gpt2.named_parameters()):\n",
        "            if \"ln\" in name or \"wpe\" in name:\n",
        "                param.requires_grad = True\n",
        "            else:\n",
        "                param.requires_grad = False\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.gpt2(inputs_embeds=x).last_hidden_state\n",
        "\n",
        "class ST_LLM(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        device,\n",
        "        adj,\n",
        "        input_dim=3,\n",
        "        # hidden dimension\n",
        "        channels=64,\n",
        "        num_nodes=170,\n",
        "        input_len=12,\n",
        "        output_len=12,\n",
        "        dropout=0.1,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        # attributes\n",
        "        self.device = device\n",
        "        self.num_nodes = num_nodes\n",
        "        self.node_dim = channels\n",
        "        self.input_len = input_len\n",
        "        self.input_dim = input_dim\n",
        "        self.output_len = output_len\n",
        "        self.adj = adj\n",
        "        self.adj = torch.Tensor(self.adj).to(self.device)\n",
        "\n",
        "        if num_nodes == 170 or num_nodes == 307:\n",
        "            time = 288\n",
        "        elif num_nodes == 250 or num_nodes == 266:\n",
        "            time = 48\n",
        "\n",
        "        gpt_channel = 768\n",
        "\n",
        "        self.start_conv = nn.Conv2d(\n",
        "            self.input_dim * self.input_len, gpt_channel, kernel_size=(1, 1)\n",
        "        )\n",
        "\n",
        "        self.gpt = GPT4TS(device=self.device, gpt_layers=6)\n",
        "\n",
        "        self.gat = GraphAttentionLayer(\n",
        "            in_features=gpt_channel,\n",
        "            out_features=gpt_channel,\n",
        "            n_heads=3 * 8,\n",
        "            is_concat=True,\n",
        "            dropout=dropout,\n",
        "        )\n",
        "\n",
        "        # regression\n",
        "        self.regression_layer = nn.Conv2d(\n",
        "            gpt_channel, self.output_len, kernel_size=(1, 1)\n",
        "        )\n",
        "\n",
        "    def param_num(self):\n",
        "        return sum(param.numel() for param in self.parameters() if param.requires_grad)\n",
        "\n",
        "    def forward(self, history_data):\n",
        "        batch_size, _, num_nodes, _ = history_data.shape\n",
        "\n",
        "        # reshape\n",
        "        history_data = history_data.transpose(1, 2).contiguous()\n",
        "        history_data = (\n",
        "            history_data.view(batch_size, num_nodes, -1).transpose(1, 2).unsqueeze(-1)\n",
        "        )\n",
        "        data_st = self.start_conv(history_data)\n",
        "\n",
        "        data_st = data_st.permute(0, 2, 3, 1)\n",
        "        data_st = data_st.view(batch_size, num_nodes, -1)\n",
        "\n",
        "        data_st = self.gat(data_st, self.adj.unsqueeze(-1)) + data_st\n",
        "        data_st = self.gpt(data_st)\n",
        "\n",
        "        data_st = data_st.permute(0, 2, 1).unsqueeze(-1)\n",
        "\n",
        "        prediction = self.regression_layer(data_st)\n",
        "        return prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iFSTnevsXj9e"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import random\n",
        "import os\n",
        "from types import SimpleNamespace\n",
        "\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:21'\n",
        "\n",
        "\n",
        "# Define or import the required classes and functions before main()\n",
        "# Placeholder: ST_LLM, MAE_torch, MAPE_torch, RMSE_torch, WMAPE_torch, load_dataset, metric\n",
        "adj = load_graph_data(\"../content/sample_data/adj_mx.pkl\") # nyc\n",
        "class trainer:\n",
        "    def __init__(self,\n",
        "        scaler,\n",
        "        input_dim,\n",
        "        channels,\n",
        "        num_nodes,\n",
        "        input_len,\n",
        "        output_len,\n",
        "        dropout,\n",
        "        lrate,\n",
        "        wdecay,\n",
        "        device,\n",
        "        adj):\n",
        "        self.model = ST_LLM(\n",
        "            adj=adj,\n",
        "            input_dim=config[\"input_dim\"],\n",
        "            channels=64,\n",
        "            num_nodes=config[\"num_nodes\"],\n",
        "            input_len=config[\"input_len\"],\n",
        "            output_len=config[\"output_len\"],\n",
        "            dropout=config[\"dropout\"],\n",
        "            #llm_layer=config[\"llm_layer\"],\n",
        "            #U=config[\"U\"],\n",
        "            device=device)\n",
        "        self.model.to(device)\n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=lrate, weight_decay=wdecay)\n",
        "        self.loss = MAE_torch\n",
        "        self.scaler = scaler\n",
        "        self.clip = 5\n",
        "        print(\"The number of parameters: {}\".format(self.model.param_num()))\n",
        "        print(self.model)\n",
        "\n",
        "    def train(self, input, real_val):\n",
        "        self.model.train()\n",
        "        self.optimizer.zero_grad()\n",
        "        output = self.model(input).transpose(1, 3)\n",
        "        real = torch.unsqueeze(real_val, dim=1)\n",
        "        predict = self.scaler.inverse_transform(output)\n",
        "        loss = self.loss(predict, real, 0.0)\n",
        "        loss.backward()\n",
        "        if self.clip is not None:\n",
        "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.clip)\n",
        "        self.optimizer.step()\n",
        "        mape = MAPE_torch(predict, real, 0.0).item()\n",
        "        rmse = RMSE_torch(predict, real, 0.0).item()\n",
        "        wmape = WMAPE_torch(predict, real, 0.0).item()\n",
        "        return loss.item(), mape, rmse, wmape\n",
        "\n",
        "    def eval(self, input, real_val):\n",
        "        self.model.eval()\n",
        "        output = self.model(input).transpose(1, 3)\n",
        "        real = torch.unsqueeze(real_val, dim=1)\n",
        "        predict = self.scaler.inverse_transform(output)\n",
        "        loss = self.loss(predict, real, 0.0)\n",
        "        mape = MAPE_torch(predict, real, 0.0).item()\n",
        "        rmse = RMSE_torch(predict, real, 0.0).item()\n",
        "        wmape = WMAPE_torch(predict, real, 0.0).item()\n",
        "        return loss.item(), mape, rmse, wmape\n",
        "\n",
        "\n",
        "def seed_it(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ[\"PYTHONSEED\"] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.enabled = True\n",
        "\n",
        "\n",
        "def main():\n",
        "    seed_it(6666)\n",
        "    data = config[\"data\"]\n",
        "\n",
        "    device = torch.device(config[\"device\"])\n",
        "    dataloader = load_dataset(\n",
        "        config[\"data\"], config[\"batch_size\"], config[\"batch_size\"], config[\"batch_size\"]\n",
        "    )\n",
        "    scaler = dataloader[\"scaler\"]\n",
        "\n",
        "    loss = 9999999\n",
        "    test_log = 999999\n",
        "    epochs_since_best_mae = 0\n",
        "    path = config[\"save\"] + data + \"/\"\n",
        "\n",
        "    his_loss = []\n",
        "    val_time = []\n",
        "    train_time = []\n",
        "    result = []\n",
        "    test_result = []\n",
        "\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "\n",
        "\n",
        "    engine = trainer(\n",
        "        scaler,\n",
        "        config[\"input_dim\"],\n",
        "        config[\"channels\"],\n",
        "        config[\"num_nodes\"],\n",
        "        config[\"input_len\"],\n",
        "        config[\"output_len\"],\n",
        "        config[\"dropout\"],\n",
        "        config[\"lrate\"],\n",
        "        config[\"wdecay\"],\n",
        "        device,\n",
        "        adj\n",
        "    )\n",
        "\n",
        "    print(\"start training...\", flush=True)\n",
        "    for i in range(1, config[\"epochs\"] + 1):\n",
        "        train_loss = []\n",
        "        train_mape = []\n",
        "        train_rmse = []\n",
        "        train_wmape = []\n",
        "\n",
        "        t1 = time.time()\n",
        "        # dataloader['train_loader'].shuffle()\n",
        "        for iter, (x, y) in enumerate(dataloader[\"train_loader\"].get_iterator()):\n",
        "            trainx = torch.Tensor(x).to(device)  # 64 12 250 1\n",
        "            trainx = trainx.transpose(1, 3)\n",
        "            trainy = torch.Tensor(y).to(device)\n",
        "            trainy = trainy.transpose(1, 3)\n",
        "            metrics = engine.train(trainx, trainy[:, 0, :, :])\n",
        "            train_loss.append(metrics[0])\n",
        "            train_mape.append(metrics[1])\n",
        "            train_rmse.append(metrics[2])\n",
        "            train_wmape.append(metrics[3])\n",
        "\n",
        "\n",
        "        t2 = time.time()\n",
        "        log = \"Epoch: {:03d}, Training Time: {:.4f} secs\"\n",
        "        print(log.format(i, (t2 - t1)))\n",
        "        train_time.append(t2 - t1)\n",
        "\n",
        "        # validation\n",
        "        valid_loss = []\n",
        "        valid_mape = []\n",
        "        valid_wmape = []\n",
        "        valid_rmse = []\n",
        "\n",
        "        s1 = time.time()\n",
        "        for iter, (x, y) in enumerate(dataloader[\"val_loader\"].get_iterator()):\n",
        "            testx = torch.Tensor(x).to(device)\n",
        "            testx = testx.transpose(1, 3)\n",
        "            testy = torch.Tensor(y).to(device)\n",
        "            testy = testy.transpose(1, 3)\n",
        "            metrics = engine.eval(testx, testy[:, 0, :, :])\n",
        "            valid_loss.append(metrics[0])\n",
        "            valid_mape.append(metrics[1])\n",
        "            valid_rmse.append(metrics[2])\n",
        "            valid_wmape.append(metrics[3])\n",
        "\n",
        "        s2 = time.time()\n",
        "\n",
        "        log = \"Epoch: {:03d}, Inference Time: {:.4f} secs\"\n",
        "        print(log.format(i, (s2 - s1)))\n",
        "        val_time.append(s2 - s1)\n",
        "\n",
        "        mtrain_loss = np.mean(train_loss)\n",
        "        mtrain_mape = np.mean(train_mape)\n",
        "        mtrain_wmape = np.mean(train_wmape)\n",
        "        mtrain_rmse = np.mean(train_rmse)\n",
        "\n",
        "        mvalid_loss = np.mean(valid_loss)\n",
        "        mvalid_mape = np.mean(valid_mape)\n",
        "        mvalid_wmape = np.mean(valid_wmape)\n",
        "        mvalid_rmse = np.mean(valid_rmse)\n",
        "\n",
        "        his_loss.append(mvalid_loss)\n",
        "        print(\"-----------------------\")\n",
        "\n",
        "        train_m = dict(\n",
        "            train_loss=np.mean(train_loss),\n",
        "            train_rmse=np.mean(train_rmse),\n",
        "            train_mape=np.mean(train_mape),\n",
        "            train_wmape=np.mean(train_wmape),\n",
        "            valid_loss=np.mean(valid_loss),\n",
        "            valid_rmse=np.mean(valid_rmse),\n",
        "            valid_mape=np.mean(valid_mape),\n",
        "            valid_wmape=np.mean(valid_wmape),\n",
        "        )\n",
        "        train_m = pd.Series(train_m)\n",
        "        result.append(train_m)\n",
        "\n",
        "        log = \"Epoch: {:03d}, Train Loss: {:.4f}, Train RMSE: {:.4f}, Train MAPE: {:.4f}, Train WMAPE: {:.4f}, \"\n",
        "        print(\n",
        "            log.format(i, mtrain_loss, mtrain_rmse, mtrain_mape, mtrain_wmape),\n",
        "            flush=True,\n",
        "        )\n",
        "        log = \"Epoch: {:03d}, Valid Loss: {:.4f}, Valid RMSE: {:.4f}, Valid MAPE: {:.4f}, Valid WMAPE: {:.4f}\"\n",
        "        print(\n",
        "            log.format(i, mvalid_loss, mvalid_rmse, mvalid_mape, mvalid_wmape),\n",
        "            flush=True,\n",
        "        )\n",
        "\n",
        "        if mvalid_loss < loss:\n",
        "            print(\"###Update tasks appear###\")\n",
        "            if i <= 100:\n",
        "                # It is not necessary to print the results of the test set when epoch is less than 100, because the model has not yet converged.\n",
        "                loss = mvalid_loss\n",
        "                torch.save(engine.model.state_dict(), path + \"best_model.pth\")\n",
        "                bestid = i\n",
        "                epochs_since_best_mae = 0\n",
        "                print(\"Updating! Valid Loss:{:.4f}\".format(mvalid_loss), end=\", \")\n",
        "                print(\"epoch: \", i)\n",
        "\n",
        "            else:\n",
        "                loss = mvalid_loss\n",
        "                torch.save(engine.model.state_dict(), path + \"best_model.pth\")\n",
        "                bestid = i\n",
        "                epochs_since_best_mae = 0\n",
        "                print(\"Updating! Valid Loss:{:.4f}\".format(mvalid_loss), end=\", \")\n",
        "                print(\"epoch: \", i)\n",
        "\n",
        "                outputs = []\n",
        "                realy = torch.Tensor(dataloader[\"y_test\"]).to(device)\n",
        "                realy = realy.transpose(1, 3)[:, 0, :, :]\n",
        "\n",
        "                for iter, (x, y) in enumerate(dataloader[\"test_loader\"].get_iterator()):\n",
        "                    testx = torch.Tensor(x).to(device)\n",
        "                    testx = testx.transpose(1, 3)\n",
        "                    with torch.no_grad():\n",
        "                        preds = engine.model(testx).transpose(1, 3)\n",
        "                    outputs.append(preds.squeeze())\n",
        "\n",
        "                yhat = torch.cat(outputs, dim=0)\n",
        "                yhat = yhat[: realy.size(0), ...]\n",
        "\n",
        "                amae = []\n",
        "                amape = []\n",
        "                awmape = []\n",
        "                armse = []\n",
        "\n",
        "                for j in range(config[\"output_len\"]):\n",
        "                    pred = scaler.inverse_transform(yhat[:, :, j])\n",
        "                    real = realy[:, :, j]\n",
        "                    metrics = metric(pred, real)\n",
        "                    # log = \"Evaluate best model on test data for horizon {:d}, Test MAE: {:.4f}, Test RMSE: {:.4f}, Test MAPE: {:.4f}, Test WMAPE: {:.4f}\"\n",
        "                    # print(\n",
        "                    #     log.format(\n",
        "                    #         j + 1, metrics[0], metrics[2], metrics[1], metrics[3]\n",
        "                    #     )\n",
        "                    # )\n",
        "\n",
        "                    amae.append(metrics[0])\n",
        "                    amape.append(metrics[1])\n",
        "                    armse.append(metrics[2])\n",
        "                    awmape.append(metrics[3])\n",
        "\n",
        "                log = \"On average over 12 horizons, Test MAE: {:.4f}, Test RMSE: {:.4f}, Test MAPE: {:.4f}, Test WMAPE: {:.4f}\"\n",
        "                print(\n",
        "                    log.format(\n",
        "                        np.mean(amae), np.mean(armse), np.mean(amape), np.mean(awmape)\n",
        "                    )\n",
        "                )\n",
        "\n",
        "                if np.mean(amae) < test_log:\n",
        "                    test_log = np.mean(amae)\n",
        "                    print(f\"Test low! Updating! Test Loss: {test_log:.4f}, Valid Loss: {mvalid_loss:.4f}, epoch: {i}\")\n",
        "                else:\n",
        "                    epochs_since_best_mae += 1\n",
        "                    print(\"No update\")\n",
        "\n",
        "        else:\n",
        "            epochs_since_best_mae += 1\n",
        "            print(\"No update\")\n",
        "\n",
        "        train_csv = pd.DataFrame(result)\n",
        "        train_csv.round(8).to_csv(f\"{path}/train.csv\")\n",
        "\n",
        "        # Early stop\n",
        "        if epochs_since_best_mae >= config[\"es_patience\"] and i >= 200:\n",
        "            break\n",
        "\n",
        "    # Output consumption\n",
        "    print(\"Average Training Time: {:.4f} secs/epoch\".format(np.mean(train_time)))\n",
        "    print(\"Average Inference Time: {:.4f} secs\".format(np.mean(val_time)))\n",
        "\n",
        "    # test\n",
        "    print(\"Training ends\")\n",
        "    print(\"The epoch of the best resultï¼š\", bestid)\n",
        "    print(\"The valid loss of the best model\", str(round(his_loss[bestid - 1], 4)))\n",
        "\n",
        "    engine.model.load_state_dict(torch.load(path + \"best_model.pth\"))\n",
        "    outputs = []\n",
        "    realy = torch.Tensor(dataloader[\"y_test\"]).to(device)\n",
        "    realy = realy.transpose(1, 3)[:, 0, :, :]\n",
        "\n",
        "    for iter, (x, y) in enumerate(dataloader[\"test_loader\"].get_iterator()):\n",
        "        testx = torch.Tensor(x).to(device)\n",
        "        testx = testx.transpose(1, 3)\n",
        "        with torch.no_grad():\n",
        "            preds = engine.model(testx).transpose(1, 3)\n",
        "        outputs.append(preds.squeeze())\n",
        "\n",
        "    yhat = torch.cat(outputs, dim=0)\n",
        "    yhat = yhat[: realy.size(0), ...]\n",
        "\n",
        "    amae = []\n",
        "    amape = []\n",
        "    armse = []\n",
        "    awmape = []\n",
        "\n",
        "    test_m = []\n",
        "\n",
        "    for i in range(config[\"output_len\"]):\n",
        "        pred = scaler.inverse_transform(yhat[:, :, i])\n",
        "        real = realy[:, :, i]\n",
        "        metrics = metric(pred, real)\n",
        "        # log = \"Evaluate best model on test data for horizon {:d}, Test MAE: {:.4f}, Test RMSE: {:.4f}, Test MAPE: {:.4f}, Test WMAPE: {:.4f}\"\n",
        "        # print(log.format(i + 1, metrics[0], metrics[2], metrics[1], metrics[3]))\n",
        "\n",
        "        test_m = dict(\n",
        "            test_loss=np.mean(metrics[0]),\n",
        "            test_rmse=np.mean(metrics[2]),\n",
        "            test_mape=np.mean(metrics[1]),\n",
        "            test_wmape=np.mean(metrics[3]),\n",
        "        )\n",
        "        test_m = pd.Series(test_m)\n",
        "        test_result.append(test_m)\n",
        "\n",
        "        amae.append(metrics[0])\n",
        "        amape.append(metrics[1])\n",
        "        armse.append(metrics[2])\n",
        "        awmape.append(metrics[3])\n",
        "\n",
        "    log = \"On average over 12 horizons, Test MAE: {:.4f}, Test RMSE: {:.4f}, Test MAPE: {:.4f}, Test WMAPE: {:.4f}\"\n",
        "    print(log.format(np.mean(amae), np.mean(armse), np.mean(amape), np.mean(awmape)))\n",
        "\n",
        "    test_m = dict(\n",
        "        test_loss=np.mean(amae),\n",
        "        test_rmse=np.mean(armse),\n",
        "        test_mape=np.mean(amape),\n",
        "        test_wmape=np.mean(awmape),\n",
        "    )\n",
        "    test_m = pd.Series(test_m)\n",
        "    test_result.append(test_m)\n",
        "\n",
        "    test_csv = pd.DataFrame(test_result)\n",
        "    test_csv.round(8).to_csv(f\"{path}/test.csv\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    torch.cuda.empty_cache()\n",
        "    t1 = time.time()\n",
        "    main()\n",
        "    t2 = time.time()\n",
        "    print(\"Total time spent: {:.4f}\".format(t2 - t1))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
